# Cybersecurity Audit - Control IA-06

## Control Information

- **Control ID**: IA-06
- **Control Name**: Output Filtering
- **Audit Date**: 2025-01-27
- **Client Question**: "Do you apply filters on the responses generated by the AI?"

---

## Executive Summary

❌ **NON-COMPLIANT**: The platform does not implement output filtering controls to prevent toxic or sensitive outputs from AI responses. The system relies exclusively on system prompts stored in Supabase to guide AI behavior, but there are no technical filters, content validation mechanisms, or post-processing controls to block or sanitize inappropriate responses. The agent can generate responses on any topic, including content unrelated to industrial procurement, with no filtering mechanism to prevent such outputs.

1. **No Output Filtering Implementation** - No technical filters or content validation applied to AI responses
2. **System Prompt Dependency** - Relies solely on system prompts without enforcement mechanisms
3. **Direct Response Transmission** - AI responses are passed directly to users without filtering or validation
4. **No Topic Restriction Enforcement** - No mechanism prevents responses unrelated to industrial procurement
5. **No Content Policy Validation** - No validation against content policies or sensitive content detection

---

## 1. System Architecture Overview

### 1.1. AI Response Flow

The platform processes AI responses through multiple nodes and agents, but all responses flow directly to users without filtering:

```
User Input
    ↓
Router Node / Agent Node
    ↓
LLM (OpenAI API)
    ↓
Response Processing
    ↓
Direct Output to User (NO FILTERING)
```

**Analysis**: The response flow shows no intermediate filtering or validation steps between LLM generation and user delivery.

### 1.2. Response Processing Components

The platform uses several components to process AI responses:

1. **BaseNode** (`agent/core/base_node.py`) - Base class for all agent nodes
2. **AgentNode** (`agent/core/base_node.py`) - Handles agent responses with tools
3. **SimpleNode** (`agent/core/base_node.py`) - Handles simple LLM responses
4. **GeneralNode** (`agent/nodes/general_node.py`) - Processes general queries
5. **RFX Conversational Agent** (`agent/rfx_conversational_agent.py`) - Handles RFX-specific conversations

**Evidence**:
```python
// agent/core/base_node.py
def _process_agent_response(self, response, streaming_handler, state) -> Dict[str, Any]:
    """Procesa la respuesta del agente."""
    # Señalar el final del streaming
    streaming_handler.on_stream_end()
    
    # El create_react_agent devuelve un dict con "messages"
    output_text = ""
    if isinstance(response, dict) and "messages" in response:
        messages = response.get("messages", [])
        if messages:
            last_msg = messages[-1]
            if hasattr(last_msg, "content"):
                output_text = last_msg.content
            elif isinstance(last_msg, dict):
                output_text = last_msg.get("content", "")
    
    # Priorizar texto de streaming si existe
    if streaming_handler.get_text():
        output_text = streaming_handler.get_text()
    
    # Extraer resultados de herramientas
    tool_results = self._extract_tool_results(response)
    
    return {
        "output": output_text,  # Direct output, no filtering
        "tool_result": tool_results
    }
```

**Analysis**: The response processing extracts the output text directly from the LLM response without any filtering, validation, or content checking.

---

## 2. System Prompt Configuration

### 2.1. System Prompt Loading

System prompts are loaded from Supabase and used to guide AI behavior, but they are not enforced through technical controls.

**Evidence**:
```python
// agent/tools/llm_config.py
def load_prompts_and_llm_params():
    """
    Loads ALL prompts and LLM parameters from Supabase without fallbacks.
    If loading fails, raises an exception.
    """
    row = _get_active_row()
    
    # Unified dictionary with ALL prompts
    prompts = {
        "system": _safe_prompt_conversion(row["system_prompt"]),
        "recommendation": _safe_prompt_conversion(row["recommendation_prompt"]), 
        "lookup": _safe_prompt_conversion(row["lookup_prompt"]),
        "router": _safe_prompt_conversion(row["router_prompt"]),
        "rfx_conversational_system": _safe_prompt_conversion(row.get("rfx_conversational_system_prompt")),
        "propose_edits_system": _safe_prompt_conversion(row.get("propose_edits_system_prompt")),
        # ... other prompts
    }
       
    return prompts, llm_params
```

**Analysis**: System prompts are loaded from the database and passed to LLMs, but there is no mechanism to enforce that responses comply with these prompts.

### 2.2. System Prompt Usage in Nodes

System prompts are used in all agent nodes, but responses are not validated against them.

**Evidence**:
```python
// agent/nodes/general_node.py
def _prepare_messages(self, state: ChatState, prompts) -> List[Dict[str, str]]:
    """Prepara los mensajes para la API de OpenAI."""
    SYSTEM_PROMPT = prompts["system"]
    # ... prompt preparation ...
    
    # Construir mensajes
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    # ... add user messages ...
    
    return messages
```

**Evidence**:
```python
// agent/rfx_conversational_agent.py
def _build_messages(chat_history: List[Dict[str, Any]], content: str) -> List:
    """
    Construye los mensajes para el agente.
    """
    # Load system prompt from Supabase (strict, no fallback)
    system_prompt = get_rfx_conversational_prompt()
    msgs = [SystemMessage(content=system_prompt)]
    # ... add chat history and user message ...
    return msgs
```

**Analysis**: System prompts are included in messages sent to LLMs, but the responses are not checked to ensure they comply with the prompt instructions or stay within the intended domain scope.

---

## 3. Response Transmission Without Filtering

### 3.1. Direct Response Output

All AI responses are transmitted directly to users through WebSocket connections without any filtering layer.

**Evidence**:
```python
// agent/core/base_node.py
def _update_chat_history(self, state: ChatState, result: Dict[str, Any]) -> Dict[str, Any]:
    """Actualiza el historial de chat con la respuesta."""
    chat_history = state.get("chat_history", [])
    user_input = state["input"]
    output_text = result.get("output", "")
    
    # Agregar entrada del usuario
    chat_history.append({"role": "user", "content": user_input})
    
    # Agregar respuesta del asistente (direct output, no filtering)
    chat_history.append({"role": "assistant", "content": output_text})
    
    result["chat_history"] = chat_history
    return result
```

**Analysis**: The output text is added directly to chat history and returned to users without any content validation or filtering.

### 3.2. Streaming Response Handling

Streaming responses are also transmitted directly without filtering.

**Evidence**:
```python
// agent/core/base_node.py
def _process_agent_response(self, response, streaming_handler, state) -> Dict[str, Any]:
    """Procesa la respuesta del agente."""
    streaming_handler.on_stream_end()
    
    # Priorizar texto de streaming si existe
    if streaming_handler.get_text():
        output_text = streaming_handler.get_text()  # Direct streaming text, no filtering
    
    return {
        "output": output_text,  # Returned directly
        "tool_result": tool_results
    }
```

**Analysis**: Streaming responses are collected and returned directly without any intermediate filtering or validation step.

### 3.3. WebSocket Response Transmission

Responses are sent to users via WebSocket without filtering.

**Evidence**:
```python
// api/webserver.py (conceptual flow)
# After agent execution
output_text = result.get("output", "")
# ... 
# Send directly to WebSocket
await websocket.send_json({
    "type": "agent_response",
    "data": output_text  # Direct transmission, no filtering
})
```

**Analysis**: The WebSocket transmission sends responses directly to clients without any content filtering or validation layer.

---

## 4. Lack of Content Filtering Mechanisms

### 4.1. No Toxic Content Detection

The codebase contains no implementation of toxic content detection or filtering.

**Evidence**: Search results show no references to:
- Toxic content detection
- Content moderation
- Inappropriate content filtering
- Content policy validation
- Output sanitization

**Analysis**: There are no mechanisms to detect or filter toxic, harmful, or inappropriate content in AI responses.

### 4.2. No Topic Restriction Enforcement

While system prompts may instruct the AI to focus on industrial procurement, there is no technical enforcement to prevent off-topic responses.

**Evidence**:
```python
// agent/nodes/general_node.py
def _prepare_messages(self, state: ChatState, prompts) -> List[Dict[str, str]]:
    SYSTEM_PROMPT = prompts["system"]  # May contain domain restrictions
    # ... 
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    # No validation that response stays on topic
```

**Analysis**: System prompts may contain instructions to stay within the industrial procurement domain, but there is no code that validates responses against these restrictions or filters out off-topic content.

### 4.3. No Response Validation

Responses are not validated against any content policies or rules.

**Evidence**: No code found that:
- Validates response content against policies
- Checks for sensitive information
- Filters inappropriate language
- Enforces domain restrictions
- Validates response format or content

**Analysis**: The system trusts LLM responses completely and transmits them without validation.

---

## 5. System Prompt Limitations

### 5.1. Prompt-Based Guidance Only

System prompts provide guidance but are not enforced technically.

**Evidence**:
```python
// agent/tools/llm_config.py
prompts = {
    "system": _safe_prompt_conversion(row["system_prompt"]),
    # Prompts are loaded and used, but not enforced
}
```

**Analysis**: System prompts are instructional only. They guide the AI's behavior but cannot prevent the AI from generating responses that violate the instructions, as there is no technical enforcement mechanism.

### 5.2. No Prompt Compliance Checking

There is no mechanism to verify that responses comply with system prompt instructions.

**Evidence**: No code found that:
- Compares responses to prompt instructions
- Validates response relevance to the domain
- Checks for prompt compliance
- Enforces prompt constraints

**Analysis**: The system assumes LLMs will follow prompt instructions, but does not verify or enforce compliance.

---

## 6. Comparison with Industry Standards

### 6.1. Expected Output Filtering Controls

Industry-standard output filtering typically includes:

1. **Content Moderation APIs** - Integration with services that detect toxic content
2. **Keyword Filtering** - Blocking specific words or phrases
3. **Topic Validation** - Ensuring responses stay within domain scope
4. **Response Sanitization** - Removing or redacting sensitive information
5. **Policy Enforcement** - Technical validation against content policies

**Analysis**: The platform implements none of these standard output filtering controls.

### 6.2. Current Implementation Gap

The platform's current approach:

- ✅ Uses system prompts to guide behavior
- ❌ Does not filter or validate responses
- ❌ Does not enforce domain restrictions
- ❌ Does not detect toxic or sensitive content
- ❌ Does not sanitize outputs

**Analysis**: The gap between expected controls and current implementation represents a significant security and compliance risk.

---

## 7. Conclusions

### 7.1. Strengths

✅ **System Prompt Configuration**: The platform uses a centralized system for managing system prompts through Supabase, allowing for prompt updates without code changes.

✅ **Modular Architecture**: The separation of concerns between nodes, agents, and response processing provides a foundation where filtering could be added.

✅ **Response Processing Infrastructure**: The response processing pipeline has clear entry points where filtering could be implemented.

### 7.2. Recommendations

1. **Implement Content Moderation API Integration**: Integrate a content moderation service (e.g., OpenAI's moderation API, Perspective API, or Azure Content Moderator) to detect and filter toxic, harmful, or inappropriate content before responses are sent to users.

2. **Add Response Validation Layer**: Implement a validation layer that checks responses against content policies, domain restrictions, and safety guidelines. Responses that fail validation should be blocked or sanitized.

3. **Enforce Domain Restrictions**: Implement technical controls to ensure responses stay within the industrial procurement domain. This could include:
   - Topic classification of responses
   - Relevance scoring against the domain
   - Automatic rejection of clearly off-topic responses

4. **Implement Response Sanitization**: Add sanitization mechanisms to remove or redact sensitive information, PII, or inappropriate content from responses.

5. **Add Content Policy Validation**: Create a content policy engine that validates all responses against defined policies before transmission. Policies should be configurable and enforceable.

6. **Implement Logging and Monitoring**: Add logging for filtered responses and monitoring for content policy violations to enable auditing and continuous improvement of filtering mechanisms.

7. **Add Response Filtering Configuration**: Create configuration options to enable/disable filtering, adjust sensitivity levels, and customize filtering rules based on use case requirements.

8. **Implement Fallback Responses**: When responses are filtered, provide appropriate fallback responses that inform users that the requested content could not be generated while maintaining helpfulness.

---

## 8. Control Compliance

| Criterion | Status | Evidence |
|-----------|--------|----------|
| Output filtering controls implemented | ❌ NON-COMPLIANT | No filtering mechanisms found in codebase |
| Toxic content detection | ❌ NON-COMPLIANT | No toxic content detection implemented |
| Sensitive content filtering | ❌ NON-COMPLIANT | No sensitive content filtering implemented |
| Domain restriction enforcement | ❌ NON-COMPLIANT | No technical enforcement of domain restrictions |
| Content policy validation | ❌ NON-COMPLIANT | No content policy validation implemented |
| Response sanitization | ❌ NON-COMPLIANT | No response sanitization mechanisms |
| Post-processing validation | ❌ NON-COMPLIANT | Responses transmitted directly without validation |

**FINAL VERDICT**: ❌ **NON-COMPLIANT** with control IA-06. The platform does not implement any output filtering controls to prevent toxic or sensitive outputs from AI responses. The system relies exclusively on system prompts stored in Supabase to guide AI behavior, but there are no technical filters, content validation mechanisms, or post-processing controls to block or sanitize inappropriate responses. The agent can generate responses on any topic, including content unrelated to industrial procurement, with no filtering mechanism to prevent such outputs. This represents a significant security and compliance gap that requires immediate attention.

---

## Appendices

### A. Response Flow Diagram

```
User Input
    ↓
[Router/Agent Node]
    ↓
[System Prompt Applied]
    ↓
[LLM Generation]
    ↓
[Response Extraction]
    ↓
[Direct Output] ← NO FILTERING LAYER
    ↓
[WebSocket Transmission]
    ↓
User Receives Response
```

This diagram illustrates the absence of any filtering or validation step in the response flow.

### B. System Prompt Locations

System prompts are loaded from Supabase table `agent_prompt_backups_v2` and used in:

1. **General Node** (`agent/nodes/general_node.py`) - Uses `system_prompt`
2. **Lookup Node** (`agent/nodes/lookup_node.py`) - Uses `lookup_prompt`
3. **Recommendation Node** (`agent/nodes/recommendation_node.py`) - Uses `recommendation_prompt`
4. **RFX Conversational Agent** (`agent/rfx_conversational_agent.py`) - Uses `rfx_conversational_system_prompt`
5. **Propose Edits Tool** (`agent/tools/propose_edits.py`) - Uses `propose_edits_system_prompt`
6. **Evaluation Tools** (`agent/tools/helpers/llm_async.py`) - Uses `evaluations_system_prompt` and `company_evaluation_system_prompt`

All prompts are instructional only and not enforced through technical controls.

### C. Recommended Filtering Implementation Points

Filtering could be implemented at these key points:

1. **After LLM Response Extraction** (`agent/core/base_node.py::_process_agent_response`)
   - Filter before adding to chat history
   - Validate against content policies

2. **Before WebSocket Transmission** (`api/webserver.py`)
   - Final validation before sending to users
   - Last chance to filter inappropriate content

3. **In Streaming Handler** (`agent/core/streaming_handler.py`)
   - Real-time filtering during streaming
   - Early detection of problematic content

4. **In Response Processing** (`agent/core/base_node.py::_update_chat_history`)
   - Validate before persisting to chat history
   - Ensure only compliant responses are stored

### D. Content Moderation API Integration Example

A recommended implementation pattern:

```python
def filter_response(response_text: str) -> Tuple[bool, str]:
    """
    Filters response text using content moderation API.
    Returns (is_safe, filtered_text)
    """
    # Example: OpenAI Moderation API
    from openai import OpenAI
    client = OpenAI()
    
    moderation_result = client.moderations.create(input=response_text)
    
    if moderation_result.results[0].flagged:
        # Content is flagged as inappropriate
        return False, "I apologize, but I cannot provide that response."
    
    # Additional domain validation
    if not is_domain_relevant(response_text):
        return False, "I can only assist with industrial procurement questions."
    
    return True, response_text
```

This pattern would need to be integrated into the response processing pipeline.

---

**End of Audit Report - Control IA-06**

